{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..running\n",
      "Epoch: 0, train nll=1868.475830078125, val nll=1868.2834375\n",
      "saved!\n",
      "Epoch: 1, train nll=1859.985595703125, val nll=1859.9153229166666\n",
      "saved!\n",
      "Epoch: 2, train nll=1851.6258544921875, val nll=1851.7201770833333\n",
      "saved!\n",
      "Epoch: 3, train nll=1843.6077880859375, val nll=1843.4612291666667\n",
      "saved!\n",
      "Epoch: 4, train nll=1835.595458984375, val nll=1835.5020520833334\n",
      "saved!\n",
      "Epoch: 5, train nll=1827.864501953125, val nll=1827.7071354166667\n",
      "saved!\n",
      "Epoch: 6, train nll=1819.6195068359375, val nll=1819.5307291666666\n",
      "saved!\n",
      "Epoch: 7, train nll=1811.6295166015625, val nll=1811.6856458333334\n",
      "saved!\n",
      "Epoch: 8, train nll=1803.58349609375, val nll=1803.714\n",
      "saved!\n",
      "Epoch: 9, train nll=1795.235595703125, val nll=1795.244625\n",
      "saved!\n",
      "Epoch: 10, train nll=1787.1182861328125, val nll=1786.9579583333334\n",
      "saved!\n",
      "Epoch: 11, train nll=1779.1593017578125, val nll=1778.9910625\n",
      "saved!\n",
      "Epoch: 12, train nll=1770.8480224609375, val nll=1770.78509375\n",
      "saved!\n",
      "Epoch: 13, train nll=1762.708740234375, val nll=1762.7255729166666\n",
      "saved!\n",
      "Epoch: 14, train nll=1754.6920166015625, val nll=1754.5804270833332\n",
      "saved!\n",
      "Epoch: 15, train nll=1746.570068359375, val nll=1746.7195104166667\n",
      "saved!\n",
      "Epoch: 16, train nll=1738.1658935546875, val nll=1737.94434375\n",
      "saved!\n",
      "Epoch: 17, train nll=1729.715576171875, val nll=1729.67678125\n",
      "saved!\n",
      "Epoch: 18, train nll=1720.6859130859375, val nll=1720.5669791666667\n",
      "saved!\n",
      "Epoch: 19, train nll=1714.311279296875, val nll=1714.0899895833334\n",
      "saved!\n",
      "Epoch: 20, train nll=1705.4859619140625, val nll=1705.5325208333334\n",
      "saved!\n",
      "Epoch: 21, train nll=1697.1873779296875, val nll=1697.1196770833333\n",
      "saved!\n",
      "Epoch: 22, train nll=1690.0845947265625, val nll=1689.83678125\n",
      "saved!\n",
      "Epoch: 23, train nll=1681.4761962890625, val nll=1681.5462916666668\n",
      "saved!\n",
      "Epoch: 24, train nll=1673.6546630859375, val nll=1673.7807395833333\n",
      "saved!\n",
      "Epoch: 25, train nll=1664.3038330078125, val nll=1664.3223541666666\n",
      "saved!\n",
      "Epoch: 26, train nll=1656.8922119140625, val nll=1656.930125\n",
      "saved!\n",
      "Epoch: 27, train nll=1648.943603515625, val nll=1648.5633958333333\n",
      "saved!\n",
      "Epoch: 28, train nll=1640.4742431640625, val nll=1640.260875\n",
      "saved!\n",
      "Epoch: 29, train nll=1632.2000732421875, val nll=1632.3848958333333\n",
      "saved!\n",
      "Epoch: 30, train nll=1623.5419921875, val nll=1623.7968229166668\n",
      "saved!\n",
      "Epoch: 31, train nll=1617.406005859375, val nll=1617.396875\n",
      "saved!\n",
      "Epoch: 32, train nll=1608.586181640625, val nll=1608.20515625\n",
      "saved!\n",
      "Epoch: 33, train nll=1600.5787353515625, val nll=1600.3003958333334\n",
      "saved!\n",
      "Epoch: 34, train nll=1592.2711181640625, val nll=1592.1660625\n",
      "saved!\n",
      "Epoch: 35, train nll=1584.5455322265625, val nll=1584.6677291666667\n",
      "saved!\n",
      "Epoch: 36, train nll=1576.4173583984375, val nll=1576.0409270833334\n",
      "saved!\n",
      "Epoch: 37, train nll=1567.9757080078125, val nll=1568.0134270833332\n",
      "saved!\n",
      "Epoch: 38, train nll=1560.4449462890625, val nll=1560.5733541666666\n",
      "saved!\n",
      "Epoch: 39, train nll=1551.78125, val nll=1551.84478125\n",
      "saved!\n",
      "Epoch: 40, train nll=1544.5081787109375, val nll=1544.3488125\n",
      "saved!\n",
      "Epoch: 41, train nll=1536.35546875, val nll=1535.9601145833333\n",
      "saved!\n",
      "Epoch: 42, train nll=1527.704345703125, val nll=1527.7633854166668\n",
      "saved!\n",
      "Epoch: 43, train nll=1520.474609375, val nll=1520.4527916666666\n",
      "saved!\n",
      "Epoch: 44, train nll=1512.3048095703125, val nll=1512.2480104166666\n",
      "saved!\n",
      "Epoch: 45, train nll=1504.0894775390625, val nll=1504.1925520833333\n",
      "saved!\n",
      "Epoch: 46, train nll=1496.046630859375, val nll=1496.02203125\n",
      "saved!\n",
      "Epoch: 47, train nll=1488.1748046875, val nll=1488.2713541666667\n",
      "saved!\n",
      "Epoch: 48, train nll=1480.55419921875, val nll=1480.1697395833332\n",
      "saved!\n",
      "Epoch: 49, train nll=1472.461181640625, val nll=1472.3378333333333\n",
      "saved!\n",
      "Epoch: 50, train nll=1464.808837890625, val nll=1464.5574375\n",
      "saved!\n",
      "Epoch: 51, train nll=1456.8697509765625, val nll=1456.6957291666668\n",
      "saved!\n",
      "Epoch: 52, train nll=1448.9981689453125, val nll=1448.95215625\n",
      "saved!\n",
      "Epoch: 53, train nll=1441.390869140625, val nll=1441.2595\n",
      "saved!\n",
      "Epoch: 54, train nll=1433.3458251953125, val nll=1433.35534375\n",
      "saved!\n",
      "Epoch: 55, train nll=1425.27294921875, val nll=1425.2820520833334\n",
      "saved!\n",
      "Epoch: 56, train nll=1417.9459228515625, val nll=1417.6525520833334\n",
      "saved!\n",
      "Epoch: 57, train nll=1409.9813232421875, val nll=1410.1835520833333\n",
      "saved!\n",
      "Epoch: 58, train nll=1402.03662109375, val nll=1402.2327395833333\n",
      "saved!\n",
      "Epoch: 59, train nll=1394.276123046875, val nll=1394.03928125\n",
      "saved!\n",
      "Epoch: 60, train nll=1386.6671142578125, val nll=1387.070375\n",
      "saved!\n",
      "Epoch: 61, train nll=1378.961669921875, val nll=1378.9809375\n",
      "saved!\n",
      "Epoch: 62, train nll=1370.635009765625, val nll=1370.7037395833333\n",
      "saved!\n",
      "Epoch: 63, train nll=1363.60205078125, val nll=1363.9196354166668\n",
      "saved!\n",
      "Epoch: 64, train nll=1355.87353515625, val nll=1355.5956458333333\n",
      "saved!\n",
      "Epoch: 65, train nll=1347.4967041015625, val nll=1347.9429270833334\n",
      "saved!\n",
      "Epoch: 66, train nll=1340.370361328125, val nll=1340.3108333333332\n",
      "saved!\n",
      "Epoch: 67, train nll=1333.085205078125, val nll=1333.02259375\n",
      "saved!\n",
      "Epoch: 68, train nll=1324.7098388671875, val nll=1324.795625\n",
      "saved!\n",
      "Epoch: 69, train nll=1317.60302734375, val nll=1317.3161979166666\n",
      "saved!\n",
      "Epoch: 70, train nll=1309.9678955078125, val nll=1310.30865625\n",
      "saved!\n",
      "Epoch: 71, train nll=1302.3900146484375, val nll=1302.5356770833334\n",
      "saved!\n",
      "Epoch: 72, train nll=1294.7703857421875, val nll=1294.7458645833333\n",
      "saved!\n",
      "Epoch: 73, train nll=1287.5518798828125, val nll=1287.98378125\n",
      "saved!\n",
      "Epoch: 74, train nll=1279.36279296875, val nll=1279.8526979166666\n",
      "saved!\n",
      "Epoch: 75, train nll=1271.712646484375, val nll=1272.04353125\n",
      "saved!\n",
      "Epoch: 76, train nll=1264.5687255859375, val nll=1264.3427291666667\n",
      "saved!\n",
      "Epoch: 77, train nll=1258.0970458984375, val nll=1258.1964166666667\n",
      "saved!\n",
      "Epoch: 78, train nll=1250.1265869140625, val nll=1250.65703125\n",
      "saved!\n",
      "Epoch: 79, train nll=1242.384765625, val nll=1242.2876666666666\n",
      "saved!\n",
      "Epoch: 80, train nll=1235.60986328125, val nll=1235.8815833333333\n",
      "saved!\n",
      "Epoch: 81, train nll=1227.593994140625, val nll=1227.3619166666667\n",
      "saved!\n",
      "Epoch: 82, train nll=1220.362060546875, val nll=1220.4470833333332\n",
      "saved!\n",
      "Epoch: 83, train nll=1214.304931640625, val nll=1214.8437083333333\n",
      "saved!\n",
      "Epoch: 84, train nll=1206.4549560546875, val nll=1205.7881354166666\n",
      "saved!\n",
      "Epoch: 85, train nll=1198.94921875, val nll=1198.8418645833333\n",
      "saved!\n",
      "Epoch: 86, train nll=1191.1798095703125, val nll=1190.6331354166666\n",
      "saved!\n",
      "Epoch: 87, train nll=1183.9866943359375, val nll=1183.7283541666666\n",
      "saved!\n",
      "Epoch: 88, train nll=1176.4281005859375, val nll=1176.5967708333333\n",
      "saved!\n",
      "Epoch: 89, train nll=1169.287841796875, val nll=1169.5097395833334\n",
      "saved!\n",
      "Epoch: 90, train nll=1163.2257080078125, val nll=1163.37115625\n",
      "saved!\n",
      "Epoch: 91, train nll=1157.249267578125, val nll=1156.334125\n",
      "saved!\n",
      "Epoch: 92, train nll=1147.2132568359375, val nll=1147.79309375\n",
      "saved!\n",
      "Epoch: 93, train nll=1142.2237548828125, val nll=1141.8943541666667\n",
      "saved!\n",
      "Epoch: 94, train nll=1134.051513671875, val nll=1135.0825\n",
      "saved!\n",
      "Epoch: 95, train nll=1127.649658203125, val nll=1126.9732916666667\n",
      "saved!\n",
      "Epoch: 96, train nll=1119.0836181640625, val nll=1120.6506875\n",
      "saved!\n",
      "Epoch: 97, train nll=1114.19775390625, val nll=1114.4881770833333\n",
      "saved!\n",
      "Epoch: 98, train nll=1104.697265625, val nll=1106.02771875\n",
      "saved!\n",
      "Epoch: 99, train nll=1101.2666015625, val nll=1100.116875\n",
      "saved!\n",
      "Epoch: 100, train nll=1096.9332275390625, val nll=1097.3228854166666\n",
      "saved!\n",
      "Epoch: 101, train nll=1094.4072265625, val nll=1093.8383229166666\n",
      "saved!\n",
      "Epoch: 102, train nll=1091.268310546875, val nll=1090.7884895833333\n",
      "saved!\n",
      "Epoch: 103, train nll=1088.1878662109375, val nll=1088.5200208333333\n",
      "saved!\n",
      "Epoch: 104, train nll=1084.4874267578125, val nll=1084.8549895833332\n",
      "saved!\n",
      "Epoch: 105, train nll=1081.418212890625, val nll=1081.2241145833334\n",
      "saved!\n",
      "Epoch: 106, train nll=1078.783935546875, val nll=1078.8792083333333\n",
      "saved!\n",
      "Epoch: 107, train nll=1073.431884765625, val nll=1074.1380104166667\n",
      "saved!\n",
      "Epoch: 108, train nll=1072.04248046875, val nll=1072.0431354166667\n",
      "saved!\n",
      "Epoch: 109, train nll=1068.0167236328125, val nll=1068.2698229166667\n",
      "saved!\n",
      "Epoch: 110, train nll=1064.01953125, val nll=1065.1757395833333\n",
      "saved!\n",
      "Epoch: 111, train nll=1062.070068359375, val nll=1062.8131354166667\n",
      "saved!\n",
      "Epoch: 112, train nll=1058.982421875, val nll=1058.9395\n",
      "saved!\n",
      "Epoch: 113, train nll=1055.703857421875, val nll=1055.7848125\n",
      "saved!\n",
      "Epoch: 114, train nll=1053.106201171875, val nll=1053.4305625\n",
      "saved!\n",
      "Epoch: 115, train nll=1049.1807861328125, val nll=1050.00134375\n",
      "saved!\n",
      "Epoch: 116, train nll=1046.7576904296875, val nll=1046.8365416666666\n",
      "saved!\n",
      "Epoch: 117, train nll=1042.6041259765625, val nll=1043.00134375\n",
      "saved!\n",
      "Epoch: 118, train nll=1039.3787841796875, val nll=1040.1015104166668\n",
      "saved!\n",
      "Epoch: 119, train nll=1036.540771484375, val nll=1036.8984947916667\n",
      "saved!\n",
      "Epoch: 120, train nll=1032.694580078125, val nll=1033.9333541666667\n",
      "saved!\n",
      "Epoch: 121, train nll=1030.98095703125, val nll=1031.3220416666666\n",
      "saved!\n",
      "Epoch: 122, train nll=1026.8822021484375, val nll=1027.1011302083334\n",
      "saved!\n",
      "Epoch: 123, train nll=1024.297607421875, val nll=1023.8953854166666\n",
      "saved!\n",
      "Epoch: 124, train nll=1021.6386108398438, val nll=1021.5521979166666\n",
      "saved!\n",
      "Epoch: 125, train nll=1016.8021240234375, val nll=1017.647671875\n",
      "saved!\n",
      "Epoch: 126, train nll=1014.5824584960938, val nll=1015.1650364583334\n",
      "saved!\n",
      "Epoch: 127, train nll=1011.8449096679688, val nll=1011.6969947916666\n",
      "saved!\n",
      "Epoch: 128, train nll=1008.0379638671875, val nll=1007.906765625\n",
      "saved!\n",
      "Epoch: 129, train nll=1004.5586547851562, val nll=1004.6940520833333\n",
      "saved!\n",
      "Epoch: 130, train nll=1001.142578125, val nll=1001.9988489583334\n",
      "saved!\n",
      "Epoch: 131, train nll=997.8629150390625, val nll=998.9180625\n",
      "saved!\n",
      "Epoch: 132, train nll=995.1934204101562, val nll=995.5135\n",
      "saved!\n",
      "Epoch: 133, train nll=992.9638671875, val nll=992.3436354166666\n",
      "saved!\n",
      "Epoch: 134, train nll=989.5806884765625, val nll=990.3621822916666\n",
      "saved!\n",
      "Epoch: 135, train nll=985.2742309570312, val nll=986.02415625\n",
      "saved!\n",
      "Epoch: 136, train nll=983.3091430664062, val nll=983.3678854166667\n",
      "saved!\n",
      "Epoch: 137, train nll=980.2832641601562, val nll=981.5175520833334\n",
      "saved!\n",
      "Epoch: 138, train nll=979.114990234375, val nll=978.1220416666666\n",
      "saved!\n",
      "Epoch: 139, train nll=974.4144287109375, val nll=974.9329010416667\n",
      "saved!\n",
      "Epoch: 140, train nll=970.6353759765625, val nll=971.3615\n",
      "saved!\n",
      "Epoch: 141, train nll=968.2057495117188, val nll=968.3731041666666\n",
      "saved!\n",
      "Epoch: 142, train nll=965.6292724609375, val nll=965.736125\n",
      "saved!\n",
      "Epoch: 143, train nll=963.219482421875, val nll=962.1489479166667\n",
      "saved!\n",
      "Epoch: 144, train nll=959.083251953125, val nll=960.1595572916667\n",
      "saved!\n",
      "Epoch: 145, train nll=956.005615234375, val nll=955.954671875\n",
      "saved!\n",
      "Epoch: 146, train nll=952.6069946289062, val nll=953.369046875\n",
      "saved!\n",
      "Epoch: 147, train nll=950.032470703125, val nll=950.564890625\n",
      "saved!\n",
      "Epoch: 148, train nll=948.4026489257812, val nll=948.6818333333333\n",
      "saved!\n",
      "Epoch: 149, train nll=944.2997436523438, val nll=944.37696875\n",
      "saved!\n",
      "Epoch: 150, train nll=941.9676513671875, val nll=942.061625\n",
      "saved!\n",
      "Epoch: 151, train nll=939.2368774414062, val nll=939.0341927083333\n",
      "saved!\n",
      "Epoch: 152, train nll=937.2301025390625, val nll=938.0418125\n",
      "saved!\n",
      "Epoch: 153, train nll=932.6553344726562, val nll=932.728453125\n",
      "saved!\n",
      "Epoch: 154, train nll=929.8041381835938, val nll=930.469640625\n",
      "saved!\n",
      "Epoch: 155, train nll=927.8189697265625, val nll=926.6209010416667\n",
      "saved!\n",
      "Epoch: 156, train nll=924.1277465820312, val nll=924.6841979166667\n",
      "saved!\n",
      "Epoch: 157, train nll=921.433837890625, val nll=922.4219270833333\n",
      "saved!\n",
      "Epoch: 158, train nll=918.2100830078125, val nll=917.7905520833333\n",
      "saved!\n",
      "Epoch: 159, train nll=916.1347045898438, val nll=915.8119479166667\n",
      "saved!\n",
      "Epoch: 160, train nll=910.9956665039062, val nll=911.6338854166667\n",
      "saved!\n",
      "Epoch: 161, train nll=909.0771484375, val nll=909.5157552083333\n",
      "saved!\n",
      "Epoch: 162, train nll=904.4559936523438, val nll=906.61328125\n",
      "saved!\n",
      "Epoch: 163, train nll=905.746826171875, val nll=904.9510989583333\n",
      "saved!\n",
      "Epoch: 164, train nll=900.6148071289062, val nll=901.0606302083334\n",
      "saved!\n",
      "Epoch: 165, train nll=900.630859375, val nll=900.7574791666667\n",
      "saved!\n",
      "Epoch: 166, train nll=895.1132202148438, val nll=895.4156666666667\n",
      "saved!\n",
      "Epoch: 167, train nll=891.242919921875, val nll=892.0688645833334\n",
      "saved!\n",
      "Epoch: 168, train nll=890.1744995117188, val nll=889.7235208333333\n",
      "saved!\n",
      "Epoch: 169, train nll=887.2363891601562, val nll=886.5994114583333\n",
      "saved!\n",
      "Epoch: 170, train nll=882.0443115234375, val nll=884.3961875\n",
      "saved!\n",
      "Epoch: 171, train nll=881.5900268554688, val nll=883.1274791666667\n",
      "saved!\n",
      "Epoch: 172, train nll=879.94384765625, val nll=879.9764010416667\n",
      "saved!\n",
      "Epoch: 173, train nll=881.6683959960938, val nll=881.1624270833333\n",
      "Epoch: 174, train nll=873.1591796875, val nll=873.461359375\n",
      "saved!\n",
      "Epoch: 175, train nll=873.7308349609375, val nll=874.6075729166666\n",
      "Epoch: 176, train nll=867.3096923828125, val nll=868.6161197916666\n",
      "saved!\n",
      "Epoch: 177, train nll=867.7040405273438, val nll=868.3656041666667\n",
      "saved!\n",
      "Epoch: 178, train nll=865.4292602539062, val nll=864.96509375\n",
      "saved!\n",
      "Epoch: 179, train nll=859.6591796875, val nll=860.482359375\n",
      "saved!\n",
      "Epoch: 180, train nll=858.3560791015625, val nll=859.0067135416666\n",
      "saved!\n",
      "Epoch: 181, train nll=858.3644409179688, val nll=857.9342239583333\n",
      "saved!\n",
      "Epoch: 182, train nll=854.6404418945312, val nll=854.1654947916667\n",
      "saved!\n",
      "Epoch: 183, train nll=850.6331176757812, val nll=851.6475625\n",
      "saved!\n",
      "Epoch: 184, train nll=850.8529052734375, val nll=850.5348385416667\n",
      "saved!\n",
      "Epoch: 185, train nll=847.8121948242188, val nll=848.18625\n",
      "saved!\n",
      "Epoch: 186, train nll=843.6529541015625, val nll=844.5309791666666\n",
      "saved!\n",
      "Epoch: 187, train nll=844.1573486328125, val nll=844.282234375\n",
      "saved!\n",
      "Epoch: 188, train nll=839.6047973632812, val nll=840.0470260416666\n",
      "saved!\n",
      "Epoch: 189, train nll=837.8017578125, val nll=838.2095833333333\n",
      "saved!\n",
      "Epoch: 190, train nll=835.8385009765625, val nll=835.8310625\n",
      "saved!\n",
      "Epoch: 191, train nll=832.9718017578125, val nll=831.9873333333334\n",
      "saved!\n",
      "Epoch: 192, train nll=830.7197265625, val nll=831.6749791666666\n",
      "saved!\n",
      "Epoch: 193, train nll=829.2225341796875, val nll=828.9416145833334\n",
      "saved!\n",
      "Epoch: 194, train nll=827.135498046875, val nll=828.2710364583334\n",
      "saved!\n",
      "Epoch: 195, train nll=825.4158935546875, val nll=825.6046666666666\n",
      "saved!\n",
      "Epoch: 196, train nll=824.8941650390625, val nll=825.17515625\n",
      "saved!\n",
      "Epoch: 197, train nll=818.4944458007812, val nll=819.6568645833333\n",
      "saved!\n",
      "Epoch: 198, train nll=816.7789916992188, val nll=817.6805989583333\n",
      "saved!\n",
      "Epoch: 199, train nll=815.2617797851562, val nll=814.177609375\n",
      "saved!\n",
      "Epoch: 200, train nll=815.3091430664062, val nll=815.7174010416667\n",
      "Epoch: 201, train nll=816.2703247070312, val nll=814.5663229166666\n",
      "Epoch: 202, train nll=812.0967407226562, val nll=813.2977135416667\n",
      "saved!\n",
      "Epoch: 203, train nll=810.87841796875, val nll=812.685421875\n",
      "saved!\n",
      "Epoch: 204, train nll=812.2852172851562, val nll=812.5733229166667\n",
      "saved!\n",
      "Epoch: 205, train nll=810.04150390625, val nll=810.8727291666667\n",
      "saved!\n",
      "Epoch: 206, train nll=810.7000122070312, val nll=810.6528854166667\n",
      "saved!\n",
      "Epoch: 207, train nll=809.1388549804688, val nll=808.227421875\n",
      "saved!\n",
      "Epoch: 208, train nll=806.5630493164062, val nll=806.3320104166667\n",
      "saved!\n",
      "Epoch: 209, train nll=807.42138671875, val nll=808.9258020833333\n",
      "Epoch: 210, train nll=805.4078979492188, val nll=808.4725364583334\n",
      "Epoch: 211, train nll=805.4844970703125, val nll=806.4013802083333\n",
      "Epoch: 212, train nll=805.7015991210938, val nll=804.778046875\n",
      "saved!\n",
      "Epoch: 213, train nll=803.7034301757812, val nll=804.4072083333333\n",
      "saved!\n",
      "Epoch: 214, train nll=804.1129760742188, val nll=803.0394583333333\n",
      "saved!\n",
      "Epoch: 215, train nll=799.3087158203125, val nll=801.6389895833333\n",
      "saved!\n",
      "Epoch: 216, train nll=799.9798583984375, val nll=800.4479479166666\n",
      "saved!\n",
      "Epoch: 217, train nll=801.3353271484375, val nll=801.0958229166666\n",
      "Epoch: 218, train nll=797.0759887695312, val nll=798.5132864583334\n",
      "saved!\n",
      "Epoch: 219, train nll=798.2372436523438, val nll=797.6892239583333\n",
      "saved!\n",
      "Epoch: 220, train nll=796.7212524414062, val nll=797.3324427083334\n",
      "saved!\n",
      "Epoch: 221, train nll=795.8283081054688, val nll=796.34865625\n",
      "saved!\n",
      "Epoch: 222, train nll=794.8165893554688, val nll=796.0421041666667\n",
      "saved!\n",
      "Epoch: 223, train nll=791.28076171875, val nll=792.907609375\n",
      "saved!\n",
      "Epoch: 224, train nll=790.9769897460938, val nll=791.724296875\n",
      "saved!\n",
      "Epoch: 225, train nll=791.9398193359375, val nll=791.0654583333334\n",
      "saved!\n",
      "Epoch: 226, train nll=789.6971435546875, val nll=790.593140625\n",
      "saved!\n",
      "Epoch: 227, train nll=788.6473388671875, val nll=787.9956614583333\n",
      "saved!\n",
      "Epoch: 228, train nll=788.26318359375, val nll=788.3552864583334\n",
      "Epoch: 229, train nll=787.4699096679688, val nll=788.7087291666667\n",
      "Epoch: 230, train nll=788.3126220703125, val nll=787.0363385416666\n",
      "saved!\n",
      "Epoch: 231, train nll=783.810791015625, val nll=786.4149322916667\n",
      "saved!\n",
      "Epoch: 232, train nll=784.5858764648438, val nll=784.643984375\n",
      "saved!\n",
      "Epoch: 233, train nll=783.6627197265625, val nll=784.2100677083333\n",
      "saved!\n",
      "Epoch: 234, train nll=784.253173828125, val nll=784.1964114583334\n",
      "saved!\n",
      "Epoch: 235, train nll=782.2614135742188, val nll=782.0679375\n",
      "saved!\n",
      "Epoch: 236, train nll=780.8660278320312, val nll=780.8087760416666\n",
      "saved!\n",
      "Epoch: 237, train nll=779.2462158203125, val nll=780.4950572916666\n",
      "saved!\n",
      "Epoch: 238, train nll=779.2113647460938, val nll=779.953078125\n",
      "saved!\n",
      "Epoch: 239, train nll=778.3101806640625, val nll=779.12778125\n",
      "saved!\n",
      "Epoch: 240, train nll=776.2536010742188, val nll=776.77528125\n",
      "saved!\n",
      "Epoch: 241, train nll=774.9317626953125, val nll=775.54659375\n",
      "saved!\n",
      "Epoch: 242, train nll=774.0695190429688, val nll=774.14953125\n",
      "saved!\n",
      "Epoch: 243, train nll=773.0877685546875, val nll=773.5980677083334\n",
      "saved!\n",
      "Epoch: 244, train nll=773.2801513671875, val nll=771.4219166666667\n",
      "saved!\n",
      "Epoch: 245, train nll=769.227783203125, val nll=771.6168489583333\n",
      "Epoch: 246, train nll=768.1139526367188, val nll=769.5935520833333\n",
      "saved!\n",
      "Epoch: 247, train nll=769.3590698242188, val nll=769.4241145833333\n",
      "saved!\n",
      "Epoch: 248, train nll=767.0252685546875, val nll=767.795359375\n",
      "saved!\n",
      "Epoch: 249, train nll=765.7264404296875, val nll=767.1190989583333\n",
      "saved!\n",
      "Epoch: 250, train nll=766.6992797851562, val nll=767.6673489583334\n",
      "Epoch: 251, train nll=766.1343383789062, val nll=766.2839010416667\n",
      "saved!\n",
      "Epoch: 252, train nll=766.52099609375, val nll=767.5485\n",
      "Epoch: 253, train nll=764.8417358398438, val nll=765.4110625\n",
      "saved!\n",
      "Epoch: 254, train nll=762.3331909179688, val nll=763.190890625\n",
      "saved!\n",
      "Epoch: 255, train nll=761.1472778320312, val nll=762.314375\n",
      "saved!\n",
      "Epoch: 256, train nll=759.3738403320312, val nll=760.3948802083333\n",
      "saved!\n",
      "Epoch: 257, train nll=760.8983154296875, val nll=761.4192552083333\n",
      "Epoch: 258, train nll=758.4601440429688, val nll=759.8959479166666\n",
      "saved!\n",
      "Epoch: 259, train nll=757.2365112304688, val nll=757.863234375\n",
      "saved!\n",
      "Epoch: 260, train nll=757.0081787109375, val nll=757.8721822916667\n",
      "Epoch: 261, train nll=757.9555053710938, val nll=757.8533333333334\n",
      "saved!\n",
      "Epoch: 262, train nll=757.2686157226562, val nll=756.3795677083333\n",
      "saved!\n",
      "Epoch: 263, train nll=754.9099731445312, val nll=754.860515625\n",
      "saved!\n",
      "Epoch: 264, train nll=755.1998291015625, val nll=753.5234427083333\n",
      "saved!\n",
      "Epoch: 265, train nll=754.5292358398438, val nll=753.4829010416667\n",
      "saved!\n",
      "Epoch: 266, train nll=754.421875, val nll=753.3910989583334\n",
      "saved!\n",
      "Epoch: 267, train nll=752.762451171875, val nll=752.0985052083333\n",
      "saved!\n",
      "Epoch: 268, train nll=749.9110717773438, val nll=751.0918020833333\n",
      "saved!\n",
      "Epoch: 269, train nll=750.0418701171875, val nll=750.4524427083334\n",
      "saved!\n",
      "Epoch: 270, train nll=748.3900146484375, val nll=750.4629947916667\n",
      "Epoch: 271, train nll=751.161865234375, val nll=751.4294114583333\n",
      "Epoch: 272, train nll=749.3947143554688, val nll=750.1154635416667\n",
      "saved!\n",
      "Epoch: 273, train nll=747.7151489257812, val nll=747.7547083333334\n",
      "saved!\n",
      "Epoch: 274, train nll=746.6900634765625, val nll=746.93759375\n",
      "saved!\n",
      "Epoch: 275, train nll=746.6326904296875, val nll=746.766734375\n",
      "saved!\n",
      "Epoch: 276, train nll=745.281005859375, val nll=746.2356510416666\n",
      "saved!\n",
      "Epoch: 277, train nll=747.5170288085938, val nll=747.7601458333334\n",
      "Epoch: 278, train nll=745.2471313476562, val nll=746.028109375\n",
      "saved!\n",
      "Epoch: 279, train nll=745.3627319335938, val nll=745.6249322916667\n",
      "saved!\n",
      "Epoch: 280, train nll=744.0944213867188, val nll=745.114625\n",
      "saved!\n",
      "Epoch: 281, train nll=744.3373413085938, val nll=744.2624010416666\n",
      "saved!\n",
      "Epoch: 282, train nll=744.443115234375, val nll=742.688109375\n",
      "saved!\n",
      "Epoch: 283, train nll=742.0827026367188, val nll=742.3123072916667\n",
      "saved!\n",
      "Epoch: 284, train nll=743.2830200195312, val nll=742.3053125\n",
      "saved!\n",
      "Epoch: 285, train nll=739.2129516601562, val nll=739.057640625\n",
      "saved!\n",
      "Epoch: 286, train nll=739.1905517578125, val nll=741.4290885416667\n",
      "Epoch: 287, train nll=739.6283569335938, val nll=738.6085\n",
      "saved!\n",
      "Epoch: 288, train nll=739.2630004882812, val nll=738.381859375\n",
      "saved!\n",
      "Epoch: 289, train nll=739.5317993164062, val nll=739.095640625\n",
      "Epoch: 290, train nll=735.77392578125, val nll=735.73809375\n",
      "saved!\n",
      "Epoch: 291, train nll=735.23388671875, val nll=736.3743385416667\n",
      "Epoch: 292, train nll=734.7069702148438, val nll=734.6978854166666\n",
      "saved!\n",
      "Epoch: 293, train nll=735.5588989257812, val nll=735.815640625\n",
      "Epoch: 294, train nll=735.1351928710938, val nll=735.3728385416666\n",
      "Epoch: 295, train nll=734.1570434570312, val nll=733.320703125\n",
      "saved!\n",
      "Epoch: 296, train nll=734.176513671875, val nll=734.3376927083333\n",
      "Epoch: 297, train nll=729.9947509765625, val nll=732.2237708333333\n",
      "saved!\n",
      "Epoch: 298, train nll=733.345947265625, val nll=732.754109375\n",
      "Epoch: 299, train nll=728.454345703125, val nll=729.723015625\n",
      "saved!\n",
      "Epoch: 300, train nll=730.1923217773438, val nll=730.4102708333334\n",
      "Epoch: 301, train nll=729.4291381835938, val nll=729.02696875\n",
      "saved!\n",
      "Epoch: 302, train nll=730.2696533203125, val nll=729.716109375\n",
      "Epoch: 303, train nll=728.69677734375, val nll=728.7156614583333\n",
      "saved!\n",
      "Epoch: 304, train nll=728.2548217773438, val nll=727.9358333333333\n",
      "saved!\n",
      "Epoch: 305, train nll=729.5663452148438, val nll=727.8486354166666\n",
      "saved!\n",
      "Epoch: 306, train nll=726.2132568359375, val nll=727.0456145833333\n",
      "saved!\n",
      "Epoch: 307, train nll=728.2300415039062, val nll=727.4123541666667\n",
      "Epoch: 308, train nll=728.863525390625, val nll=727.7047083333333\n",
      "Epoch: 309, train nll=729.0661010742188, val nll=728.8095729166666\n",
      "Epoch: 310, train nll=725.2396850585938, val nll=728.3294427083333\n",
      "Epoch: 311, train nll=727.3146362304688, val nll=727.2769010416666\n",
      "Epoch: 312, train nll=728.0958251953125, val nll=729.0535625\n",
      "FINAL LOSS: nll=727.419790625\n"
     ]
    }
   ],
   "source": [
    "print('..running')\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "#from pytorch_model_summary import summary\n",
    "import yaml\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from util import samples_generated, samples_real, plot_curve\n",
    "import idf\n",
    "from train import evaluation, training \n",
    "from data import load_data\n",
    "from neural_networks import nnetts\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "result_dir = 'results/exp_test'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = 'idf-4'\n",
    "\n",
    "D = 784   # input dimension\n",
    "M = D  # the number of neurons in scale (s) and translation (t) nets\n",
    "lr = 1e-4 # learning rate\n",
    "num_epochs = 500\n",
    "max_patience = 5 # Early Stopping\n",
    "num_flows = 4 # The number of invertible transformations\n",
    "lam = 0. # Regularization Hyperparameter\n",
    "n_mixtures = 3 # Number of latent mixing variables\n",
    "batch_size = 500\n",
    "hyperparameters = {'D': D, \n",
    "                   'M': M,\n",
    "                   'lr': lr,\n",
    "                   'num_epochs': num_epochs,\n",
    "                   'max_patience': max_patience,\n",
    "                   'num_flows': num_flows,\n",
    "                   'batch_size': batch_size,\n",
    "                   'lambda': lam,\n",
    "                   'n_mixtures': n_mixtures\n",
    "                    }\n",
    "with open(result_dir + '/hyperparameters.yaml', 'w') as file:\n",
    "    yaml.dump(hyperparameters, file)\n",
    "\n",
    "train_data, val_data, test_data = load_data('mnist')\n",
    "# Create data loaders\n",
    "training_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "netts = nnetts(D, M)\n",
    "model = idf.IDF4(netts, num_flows, n_mixtures = n_mixtures, D=D).to(device)\n",
    "#print(summary(model, torch.zeros(1, 64), show_input=False, show_hierarchical=False))\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "# Training procedure\n",
    "nll_val = training(name=name, result_dir = result_dir, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                   scheduler=scheduler, training_loader=training_loader, val_loader=val_loader, device=device, lam=lam)\n",
    "\n",
    "with open(result_dir + '/val_loss.txt', \"w\") as file:\n",
    "    for item in nll_val:\n",
    "        file.write(f\"{item}\\n\")\n",
    "\n",
    "test_loss = evaluation(name=result_dir + '/' + name, test_loader=test_loader)\n",
    "f = open(result_dir + '/test_loss.txt', \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "#samples_generated(result_dir + '/' + name, test_loader, 28)\n",
    "plot_curve(result_dir + '/' + name, nll_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x295ee5150>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = next(iter(val_loader)).detach().numpy()\n",
    "\n",
    "# GENERATIONS-------\n",
    "model_best = torch.load(result_dir + '/' + name + '.model')\n",
    "model_best.eval()\n",
    "\n",
    "x = model_best.sample(num_x * num_y)\n",
    "x = x.detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(num_x, num_y)\n",
    "plottable_image = np.reshape(x, (28, 28))\n",
    "ax.imshow(plottable_image, cmap='gray')\n",
    "#ax.axis('off')\n",
    "\n",
    "#plt.savefig(result_dir + '/' + name + '_generated_images' + '.pdf', bbox_inches='tight')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
