{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: jhans2cf\n",
      "Sweep URL: https://wandb.ai/rajpal906/pc_hyperparameter_optimization_test/sweeps/jhans2cf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import wandb\n",
    "from train import evaluation, training \n",
    "from data import load_data\n",
    "import numpy as np\n",
    "from util import categorical_layer_factory, hadamard_layer_factory, dense_layer_factory, mixing_layer_factory\n",
    "\n",
    "from Cirkit.cirkit.templates.region_graph import QuadTree\n",
    "from Cirkit.cirkit.symbolic.circuit import Circuit\n",
    "from Cirkit.cirkit.pipeline import PipelineContext\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'hyperparameter_optimization.ipynb'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "result_dir = 'models'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = 'pc'#Change to regularized\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "metric = {\n",
    "'name': 'test_bpd',\n",
    "'goal': 'minimize'   \n",
    "}\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "#TODO: add momentum?\n",
    "parameters_dict = {\n",
    "'input_dim': {\n",
    "    'value': 784\n",
    "    },\n",
    "'lam': {\n",
    "    'values': [0.1, 0.5, 1.0]\n",
    "    },\n",
    "'num_epochs': {\n",
    "    'value': 1\n",
    "    },\n",
    "'lr': {\n",
    "    'values': [1e-1, 1e-2, 1e-3]\n",
    "    },\n",
    "'batch_size': {\n",
    "    'values': [64, 128, 256]\n",
    "    },\n",
    "'num_input_units': {\n",
    "    'value': 8\n",
    "    },\n",
    "'num_sum_units': {\n",
    "    'value': 8\n",
    "    },\n",
    "'max_patience': {\n",
    "    'value': 30 # No patience for now, add momentum?\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"pc_hyperparameter_optimization_test\")\n",
    "\n",
    "def hyperparameter_sweep(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        train_data, val_data, test_data = load_data('mnist', binarize = False)\n",
    "        train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "        val_loader = DataLoader(val_data, batch_size=config.batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "        test_loader = DataLoader(test_data, batch_size=config.batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "        region_graph = QuadTree(shape=(28, 28))\n",
    "        symbolic_circuit = Circuit.from_region_graph(region_graph,\n",
    "                                                    num_input_units=config.num_input_units,\n",
    "                                                    num_sum_units=config.num_sum_units,\n",
    "                                                    input_factory=categorical_layer_factory,\n",
    "                                                    sum_factory=dense_layer_factory,\n",
    "                                                    prod_factory=hadamard_layer_factory,\n",
    "                                                    mixing_factory=mixing_layer_factory)\n",
    "\n",
    "        ctx = PipelineContext(\n",
    "            backend='torch',   # Choose the torch compilation backend\n",
    "            fold=True,         # Fold the circuit, this is a backend-specific compilation flag\n",
    "            semiring='lse-sum' # Use the (R, +, *) semiring, where + is the log-sum-exp and * is the sum\n",
    "        )\n",
    "        circuit = ctx.compile(symbolic_circuit).to(device)\n",
    "        pf_circuit = ctx.integrate(circuit).to(device)\n",
    "        model = (circuit, pf_circuit)\n",
    "        optimizer = torch.optim.SGD([p for p in circuit.parameters() if p.requires_grad == True], lr=config.lr, momentum=0.95)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "        _, _, model_best = training(name=name, result_dir=result_dir, max_patience=config.max_patience, num_epochs=config.num_epochs, \n",
    "                   model=model, optimizer=optimizer, scheduler=scheduler, training_loader=train_loader, \n",
    "                   val_loader=val_loader, device=device, lam=config.lam, batch_size = config.batch_size)\n",
    "        test_nll, test_bpd = evaluation(test_loader, device, model_best=model_best)\n",
    "        wandb.log({\"test_bpd\": test_bpd})\n",
    "\n",
    "wandb.agent(sweep_id, hyperparameter_sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert hyperparameter opt to .py, Figure out how to parallelize, Run on Eddie\n",
    "# TODO: Meantime - write overleaf, figure out how to evaluate FID, sampling from PC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
