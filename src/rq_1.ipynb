{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This experiment determines whether IDF's are translation invariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF by JT.\n",
      "Epoch: 0, val nll=-5.096121269480428e+29\n",
      "saved!\n",
      "Epoch: 1, val nll=-5.096121269480428e+29\n",
      "Epoch: 2, val nll=-5.096121269480428e+29\n",
      "Epoch: 3, val nll=-5.096121269480428e+29\n",
      "Epoch: 4, val nll=-5.096121269480428e+29\n",
      "Epoch: 5, val nll=-5.096121269480428e+29\n",
      "Epoch: 6, val nll=-5.096121269480428e+29\n",
      "Epoch: 7, val nll=-5.096121269480428e+29\n",
      "Epoch: 8, val nll=-5.096121269480428e+29\n",
      "Epoch: 9, val nll=-5.096121269480428e+29\n",
      "Epoch: 10, val nll=-5.096121269480428e+29\n",
      "Epoch: 11, val nll=-5.096121269480428e+29\n",
      "Epoch: 12, val nll=-5.096121269480428e+29\n",
      "Epoch: 13, val nll=-5.096121269480428e+29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m model \u001b[38;5;241m=\u001b[39m idf\u001b[38;5;241m.\u001b[39mIDF(nett, num_flows, D\u001b[38;5;241m=\u001b[39mD)\n\u001b[1;32m     53\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamax([p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m], lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m---> 54\u001b[0m nll_val \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_patience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Dissertation/Symmetry-invariant-Tractable-Generative-Models/src/train.py:37\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(name, result_dir, max_patience, num_epochs, model, optimizer, training_loader, val_loader)\u001b[0m\n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indx_batch, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_loader):\n\u001b[0;32m---> 37\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     40\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Downloads/Dissertation/Symmetry-invariant-Tractable-Generative-Models/src/idf.py:54\u001b[0m, in \u001b[0;36mIDF.forward\u001b[0;34m(self, x, reduction)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, reduction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     53\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(x)\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prior\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/Downloads/Dissertation/Symmetry-invariant-Tractable-Generative-Models/src/idf.py:65\u001b[0m, in \u001b[0;36mIDF.log_prior\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prior\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     64\u001b[0m     p \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp)\n\u001b[0;32m---> 65\u001b[0m     log_p \u001b[38;5;241m=\u001b[39m \u001b[43mlog_integer_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_p\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/Dissertation/Symmetry-invariant-Tractable-Generative-Models/src/util.py:43\u001b[0m, in \u001b[0;36mlog_integer_probability\u001b[0;34m(x, mean, logscale)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_integer_probability\u001b[39m(x, mean, logscale):\n\u001b[1;32m     39\u001b[0m     scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(logscale)\n\u001b[1;32m     41\u001b[0m     logp \u001b[38;5;241m=\u001b[39m log_min_exp(\n\u001b[1;32m     42\u001b[0m         F\u001b[38;5;241m.\u001b[39mlogsigmoid((x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m-\u001b[39m mean) \u001b[38;5;241m/\u001b[39m scale),\n\u001b[0;32m---> 43\u001b[0m         \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogsigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logp\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from pytorch_model_summary import summary\n",
    "import yaml\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from util import samples_generated, samples_real, plot_curve\n",
    "import idf\n",
    "from train import evaluation, training \n",
    "from data import load_data\n",
    "from neural_networks import nnetts\n",
    "\n",
    "batch_size = 256\n",
    "train_data, val_data, test_data = load_data('mnist')\n",
    "# Create data loaders\n",
    "training_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "result_dir = 'results/exp_2'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = 'idf'\n",
    "\n",
    "D = 784   # input dimension\n",
    "M = D * 2  # the number of neurons in scale (s) and translation (t) nets\n",
    "lr = 1e-2 # learning rate\n",
    "num_epochs = 100 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped\n",
    "num_flows = 8 # The number of invertible transformations\n",
    "\n",
    "hyperparameters = {'D': D, \n",
    "                   'M': M,\n",
    "                   'lr': lr,\n",
    "                   'num_epochs': num_epochs,\n",
    "                   'max_patience': max_patience,\n",
    "                   'num_flows': num_flows,\n",
    "                   'batch_size': batch_size\n",
    "                    }\n",
    "\n",
    "with open(result_dir + '/hyperparameters.yaml', 'w') as file:\n",
    "    yaml.dump(hyperparameters, file)\n",
    "\n",
    "nett = lambda: nn.Sequential(nn.Linear(D // 2, M), nn.LeakyReLU(),\n",
    "                            nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                            nn.Linear(M, D // 2))\n",
    "\n",
    "model = idf.IDF(nett, num_flows, D=D)\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)\n",
    "nll_val = training(name=name, result_dir = result_dir, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                       training_loader=training_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
